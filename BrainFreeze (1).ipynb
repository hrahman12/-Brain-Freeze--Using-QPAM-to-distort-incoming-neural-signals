{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# “Brain Freeze” – Using QPAM to distort incoming neural signals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I took my main inspiration from this research conducted at CCRMA Stanford: https://www.researchgate.net/publication/265165122_Sonification_and_Visualization_of_Neural_Data\n",
    "https://ccrma.stanford.edu/~mindyc/256a/final/\n",
    "\n",
    "\n",
    "This project nvestigates the feasibility and implications of Quantum Phase Amplitude Modulation (QPAM) in altering neural transmission. This abstract outlines a theoretical framework where QPAM techniques could intentionally disrupt neural pathways, analogous to inducing temporary cognitive effects such as \"brain freeze\". Having this happen on trillions of neurons would be quite loud; however here we only use a few artificial neurons. The potential applications and ethical considerations of this approach in neuroscience and cognitive research are explored, suggesting new avenues for understanding neural dynamics and therapeutic interventions and even creating some cool backing sounds!\n",
    "\n",
    "Since I have familiarity with both Qiskit and Pennylane (Another Quantum Programming Language but using Photonic Qubits) I just decided to use Pennylane due to the fact that in the future I will want to add some QML to automate it. I used Quantum Amplitude Encoding to extract and modify the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install pennylane"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we import our Incoming Neural Signals as .wav files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we use real neural signals from a rat brain played by a piano. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Audio\n",
    "from IPython.display import Image\n",
    "display(Audio(\"WakeNeurons.wav\")) #Note for this one the array data is const\n",
    "display(Audio(\"PoissonWake.wav\")) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And so, to begin making our own audio effect using a quantum computer, we first import required libraries needed and make the function to import .wav audio files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pennylane as qml\n",
    "import pennylane.numpy as np\n",
    "import scipy.io.wavfile\n",
    "import wave\n",
    "import time\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "\n",
    "\n",
    "def load_wav(filename):\n",
    "    sample_rate, data = scipy.io.wavfile.read(filename)\n",
    "    \n",
    "    if len(data.shape) == 2:\n",
    "        data = data.mean(axis=1)\n",
    "    return sample_rate, data\n",
    "\n",
    "# save wav\n",
    "def save_wav(filename, sample_rate, data):\n",
    "    scipy.io.wavfile.write(filename, sample_rate, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'PoissonWake.wav'  # encode to quantum computer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_rate, original_data = load_wav(filename)\n",
    "\n",
    "def QPAM_Encoding_Normalization(samples):\n",
    "    # Normalize the array between 0 and 2\n",
    "    normalized_arr = 2 * (samples - np.min(samples)) / (np.max(samples) - np.min(samples))\n",
    "\n",
    "    # Increase all amplitudes by 1.\n",
    "    # Halve the adjusted amplitudes.\n",
    "    # Divide by the total sum of these amplitudes.\n",
    "    # Calculate the square root of the outcome.\n",
    "\n",
    "    np_data = np.array(normalized_arr)\n",
    "    np_data += 1\n",
    "    np_data /= 2\n",
    "    sum = np.sum(np_data)\n",
    "    np_data = np_data/sum\n",
    "\n",
    "    print(np_data)\n",
    "    return np_data\n",
    "\n",
    "features = QPAM_Encoding_Normalization(original_data)\n",
    "length = features.shape[0]\n",
    "nb_qubits = math.ceil(np.log2(length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set up the device and num of qubits\n",
    "dev = qml.device('default.qubit', wires=nb_qubits)\n",
    "nb_qubits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@qml.qnode(dev)\n",
    "def circuit(f=None):\n",
    "    \n",
    "    # Embed input features into quantum amplitudes on all qubits\n",
    "    qml.AmplitudeEmbedding(features=f, wires=range(nb_qubits), pad_with=0,normalize=True)\n",
    "    \n",
    "    # Measure the state and return the probabilities of each measurement outcome\n",
    "    return qml.probs(wires=range(nb_qubits))\n",
    "results = circuit(features)\n",
    "print(f\"encoding result: {results}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_results = ((results - np.min(results)) / (np.max(results) - np.min(results))) * (32767 + 32768) - 32768\n",
    "newwave_name = f'new_{time.time()}.wav'\n",
    "quantum_samples_array = []\n",
    "with wave.open(newwave_name, 'w') as wav_file:\n",
    "    \n",
    "    wav_file.setparams((1, 2, sample_rate, length, 'NONE', 'not compressed'))\n",
    "    \n",
    "    quantum_samples_array = np.array(normalized_results, dtype=np.int16)\n",
    "    print(quantum_samples_array)\n",
    "    wav_file.writeframes(np.array(quantum_samples_array).tobytes())\n",
    "print(f\"{newwave_name} file has been created.\")\n",
    "orig_result = copy.deepcopy(normalized_results)\n",
    "copy_result = copy.deepcopy(normalized_results)\n",
    "display(Audio(newwave_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets see the frequency spectrum and the waveform of the decoded sound !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_rate, data = scipy.io.wavfile.read(newwave_name)\n",
    "print(sample_rate)\n",
    "# If stereo, convert to mono by averaging the two channels\n",
    "if len(data.shape) == 2:\n",
    "    data = data.mean(axis=1)\n",
    "\n",
    "# Perform the Fourier Transform to get frequency content\n",
    "# Use np.fft.rfft to handle real inputs and improve efficiency\n",
    "freq_data = np.fft.rfft(data)\n",
    "\n",
    "# Get the power spectrum (magnitude of the Fourier coefficients)\n",
    "power_spectrum = np.abs(freq_data)\n",
    "\n",
    "# Generate frequency axis (only for positive frequencies)\n",
    "freqs = np.fft.rfftfreq(len(data), d=1/sample_rate)\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(freqs, power_spectrum)\n",
    "plt.title(f'Frequency Content of {filename}')\n",
    "plt.xlabel('Frequency (Hz)')\n",
    "plt.ylabel('Magnitude')\n",
    "plt.yscale('log')  \n",
    "plt.xlim(0, sample_rate / 2)  # Nyquist limit\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#graphing\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(orig_result)\n",
    "plt.xlim(20000, 30000)\n",
    "plt.title(\"Array Data\")\n",
    "plt.xlabel(\"Index\")\n",
    "plt.ylabel(\"Value\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets see what happen if we \"deep freeze\" it. That is, since QPAM is probabilistic in nature, we want to see how it might sounds after going through the encoding and decoding phase multiple times. lets test the audio \"degradation\" after going through the quantum audio encoding and decoding process a couple of time to hear the fidelity. We should hear a clear change compared to the single QPAM result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_result = copy.deepcopy(orig_result) \n",
    "deepfry_quantum_samples_array = copy.deepcopy(quantum_samples_array)\n",
    "for i in range(2): #BRAINFREEEZE (change the number to make it more chilly!) \n",
    "    deepfry_result = circuit(QPAM_Encoding_Normalization(deepfry_quantum_samples_array))\n",
    "    \n",
    "    copy_result = ((deepfry_result - np.min(deepfry_result)) / (np.max(deepfry_result) - np.min(deepfry_result))) * (32767 + 32768) - 32768\n",
    "    deepfry_quantum_samples_array = np.array(copy_result, dtype=np.int16)\n",
    "\n",
    "newwave_name = f'neuron{time.time()}.wav'\n",
    "with wave.open(newwave_name, 'w') as wav_file:\n",
    "    \n",
    "    wav_file.setparams((1, 2, sample_rate, length, 'NONE', 'not compressed'))\n",
    "    \n",
    "   \n",
    "    deepfry_quantum_samples_array = np.array(copy_result, dtype=np.int16)\n",
    "    print(deepfry_quantum_samples_array)\n",
    "    wav_file.writeframes(np.array(deepfry_quantum_samples_array).tobytes())\n",
    "\n",
    "display(Audio(newwave_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Original Frequency VS. Brain Freezed!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_rate, data = scipy.io.wavfile.read(newwave_name)\n",
    "print(sample_rate)\n",
    "# If stereo, convert to mono by averaging the two channels\n",
    "if len(data.shape) == 2:\n",
    "    data = data.mean(axis=1)\n",
    "\n",
    "# Perform the Fourier Transform to get frequency content\n",
    "# Use np.fft.rfft to handle real inputs and improve efficiency\n",
    "freq_data = np.fft.rfft(data)\n",
    "\n",
    "# Get the power spectrum (magnitude of the Fourier coefficients)\n",
    "power_spectrum = np.abs(freq_data)\n",
    "\n",
    "# Generate frequency axis (only for positive frequencies)\n",
    "freqs = np.fft.rfftfreq(len(data), d=1/sample_rate)\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(freqs, power_spectrum)\n",
    "plt.title(f'Frequency Content of {filename}')\n",
    "plt.xlabel('Frequency (Hz)')\n",
    "plt.ylabel('Magnitude')\n",
    "plt.yscale('log')  # Set the y-axis to a logarithmic scale\n",
    "plt.xlim(0, sample_rate/2)  # Nyquist limit\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observing the upper segment of this frequency spectrum reveals higher frequencies after ~ 6000Hz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#graphing\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(copy_result, marker='o')\n",
    "plt.plot(orig_result, marker='x', label='Original Results')\n",
    "plt.xlim(0, 850000)\n",
    "plt.title(\"Array Data\")\n",
    "plt.xlabel(\"Index\")\n",
    "plt.ylabel(\"Value\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At approximately 30000, supplementary frequencies have arisen, validating the distortion effect created using quantum circuits. Presented below is a comparison between the original waveform (orange) and the quantum 'brainfreezed' waveform (blue)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion/Improvements\n",
    "\n",
    "The results are expected because the neural data was played as staccato and therefore there was randomness before the QPAM was used. \n",
    "- In the future I will add more variational neuronal sound patterns to be run simultaneously (perhaps with Quantum Machine Learning)\n",
    "- I will also neuron sounds that have higher frequencies and predict how the QPAM will amplify the frequencies.\n",
    "- I will also experiment with shorter wav files to see how it affects the array data.\n",
    "- I will create my own qwav files from scratch using a quantum synthesizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> https://www.blakeporterneuro.com/science/laboratory-teaching-resources/sounds-of-the-brain-neurons-and-rhythms/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> https://link.springer.com/book/10.1007/978-3-031-13909-3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> https://iccmr-quantum.github.io/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> https://github.com/erenutku97/An-Introduction-to-Quantum-Probability-Amplitude-Modulation-from-a-Compositional-Perspective"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> https://google-research.github.io/seanet/brain2music/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> https://link.springer.com/chapter/10.1007/978-3-319-76054-4_13"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> https://arxiv.org/pdf/2101.03887"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> https://www.researchgate.net/publication/366874916_Quantum_Representations_of_Sound_from_mechanical_waves_to_quantum_circuits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
